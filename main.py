import sys
import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
import fitz  # PyMuPDF
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import io
import json
from docx import Document  # Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª Word
from pptx import Presentation  # Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PowerPoint

# 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
load_dotenv()
st.set_page_config(page_title="Flomind Quiz Generator", page_icon="ğŸ¥", layout="wide")

# Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙƒÙŠ Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Tesseract
if sys.platform.startswith('win'):
    # Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø± Ø®Ø§Øµ Ø¨Ø¬Ù‡Ø§Ø²Ùƒ Ø§Ù„Ù…Ø­Ù„ÙŠ (ÙˆÙŠÙ†Ø¯ÙˆØ²)
    pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
else:
    # ÙÙŠ Ø³ÙŠØ±ÙØ±Ø§Øª Ù„ÙŠÙ†ÙƒØ³ (GitHub/Streamlit Cloud)ØŒ Ù‡Ùˆ ÙŠØ¹Ø±Ù Ø§Ù„Ù…Ø³Ø§Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    print("Assuming Linux environment for Tesseract")

# Ø¥Ø¹Ø¯Ø§Ø¯ Google API
api_key = os.getenv("GOOGLE_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# Ø¯ÙˆØ§Ù„ ØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ± Ù„Ù„Ù€ OCR
def preprocess_image_for_ocr(image):
    """
   ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØµÙˆØ±Ø© Ù‚Ø¨Ù„ Ù‚Ø±Ø§Ø¦ØªÙ‡Ø§ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    """
    # 1. ØªØ­ÙˆÙŠÙ„ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ© (Grayscale)
    image = image.convert('L')
    
    # 2. Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Contrast) Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¨Ø§Ù‡ØªØ©
    enhancer = ImageEnhance.Contrast(image)
    image = enhancer.enhance(2.0)  # Ø¶Ø§Ø¹ÙÙ†Ø§ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    
    # 3. Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯Ø© (Sharpness)
    enhancer = ImageEnhance.Sharpness(image)
    image = enhancer.enhance(1.5)

    return image

# --- Ø¯ÙˆØ§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ---
def extract_text_from_docx(file):
    doc = Document(file)
    text = "\n".join([para.text for para in doc.paragraphs])
    return text

def extract_text_from_pptx(file):
    prs = Presentation(file)
    text = []
    for slide in prs.slides:
        for shape in slide.shapes:
            if hasattr(shape, "text"):
                text.append(shape.text)
    return "\n".join(text)

def extract_text_from_txt(file):
    return file.read().decode("utf-8")

def extract_text_from_pdf(file):
    text = ""
    try:
        pdf_document = fitz.open(stream=file.read(), filetype="pdf")
        for page_num in range(len(pdf_document)):
            page = pdf_document.load_page(page_num)
            page_text = page.get_text()
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ù‚Ù„ÙŠÙ„Ø§Ù‹ (ØµÙˆØ±Ø©)ØŒ Ø´ØºÙ„ Ø§Ù„Ù€ OCR Ø§Ù„Ù…Ø­Ø³Ù†
            if len(page_text.strip()) < 50:
                pix = page.get_pixmap(dpi=300) # Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
                img = Image.open(io.BytesIO(pix.tobytes("png")))
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ù‚Ø¨Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR
                processed_img = preprocess_image_for_ocr(img)
                
                # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø®Ø§ØµØ© Ù„Ù‚Ø±Ø§Ø¡Ø© ÙƒØªÙ„ Ø§Ù„Ù†ØµÙˆØµ (psm 6)
                custom_config = r'--oem 3 --psm 6' 
                ocr_text = pytesseract.image_to_string(processed_img, lang='ara+eng', config=custom_config)
                text += ocr_text + "\n"
            else:
                text += page_text + "\n"
    except Exception as e:
        st.error(f"Error in PDF extraction: {e}")
    return text

# Ø¯Ø§Ù„Ø© Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­
def get_best_model():
    # Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Flash Ù„Ø£Ù†Ù‡ Ø§Ù„Ø£ÙØ¶Ù„ØŒ ÙˆØ¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù†Ø³ØªØ®Ø¯Ù… Pro
    try:
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        for m in available_models:
            if 'flash' in m: return m
        return "models/gemini-1.5-flash"
    except:
        return "models/gemini-pro"

# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø±
def get_questions(text, number_of_questions=5):
    if not api_key: return None
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Øµ Ø·ÙˆÙŠÙ„Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ØŒ Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ 10000 Ø­Ø±Ù Ù„ØªØ¬Ù†Ø¨ Ø§Ù…ØªÙ„Ø§Ø¡ Ø§Ù„ÙƒÙˆØªØ§
    if len(text) > 10000:
        text = text[:10000] + "\n...(Text truncated due to quota limits)"

    model_name = get_best_model()
    generation_config = {"temperature": 0.3} # Ù‚Ù„Ù„Ù†Ø§ Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ø¯Ù‚Ø© Ø£ÙƒØ«Ø±
    
    model = genai.GenerativeModel(model_name=model_name, generation_config=generation_config)

    prompt = f"""
    Role: You are an expert Professor creating an exam.
    Task: Create {number_of_questions} multiple-choice questions (MCQ) based on the provided text.
    
    ğŸ”´ CRITICAL INSTRUCTIONS (Follow Strictly):
    1. **Context Repair:** The text comes from OCR and may contain typos (e.g., "LMÃ©teyub" instead of "Interrupt"). You MUST infer the correct technical terms based on the context before asking.
    2. **Scope Constraint:** You are allowed to use your general knowledge to clarify concepts mentioned in the text, BUT you must NOT ask about topics completely absent from the text. Stick to the provided subject matter (e.g., if the text is about OS, don't ask about Networking unless linked).
    3. **Question Quality:** - Avoid trivial word-matching questions.
       - Ask conceptual questions that test understanding.
       - Distractors (wrong options) must be plausible and related to the field, not random or obviously wrong.
    4. **Language:** The questions must be in the same language as the majority of the text (Arabic or English).

    Output Format (Valid JSON Only):
    {{
      "questions": [
        {{
          "id": 1,
          "question": "Clear and precise question?",
          "options": ["Correct Answer", "Distractor 1", "Distractor 2", "Distractor 3"],
          "correct_answer": "Correct Answer",
          "explanation": "Brief explanation of why this is correct based on the text context."
        }}
      ]
    }}
    
    Source Text:
    '''{text}'''
    """
    try:
        response = model.generate_content(prompt)
        clean_json = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(clean_json)
    except Exception as e:
        st.error(f"AI Generation Error: {e}")
        return None


def main():
    st.title("ğŸ¥Flomind Quiz Generator")
    st.markdown("Turn your study materials into interactive quizzes ğŸª„")

    if "quiz_data" not in st.session_state:
        st.session_state.quiz_data = None

    if not api_key:
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙˆØ¶Ø¹ API Key")
        return

    # 1. ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„ÙÙƒ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ", type=["pdf", "docx", "pptx", "txt"])
    num_q = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©", 1, 10, 5)

    if st.button("ğŸš€ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±", type="primary"):
        if uploaded_file:
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ..."):
                file_ext = uploaded_file.name.split('.')[-1].lower()
                extracted_text = ""
                
                # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø¤Ø´Ø± Ù„Ù„Ø¨Ø¯Ø§ÙŠØ©
                uploaded_file.seek(0)

                # Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙˆØ¹
                try:
                    if file_ext == "pdf":
                        extracted_text = extract_text_from_pdf(uploaded_file)
                    elif file_ext == "docx":
                        extracted_text = extract_text_from_docx(uploaded_file)
                    elif file_ext == "pptx":
                        extracted_text = extract_text_from_pptx(uploaded_file)
                    elif file_ext == "txt":
                        extracted_text = extract_text_from_txt(uploaded_file)
                except Exception as e:
                    st.error(f"ÙØ´Ù„Øª Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")

                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Øµ
                if extracted_text and len(extracted_text.strip()) > 10:
                    # Ø¹Ø±Ø¶ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ (Debugging)
                    #with st.expander("ğŸ‘€ Ù…Ø¹Ø§ÙŠÙ†Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ (ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¬ÙˆØ¯Ø©)"):
                    #   st.text(extracted_text[:1000])

                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                    result = get_questions(extracted_text, num_q)
                    if result:
                        st.session_state.quiz_data = result.get("questions", [])
                        st.success("ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰")
                else:
                    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙŠ Ø§Ù„Ù…Ù„Ù.")
        else:
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù Ø£ÙˆÙ„Ø§Ù‹.")

    st.divider()

    # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
    if st.session_state.quiz_data:
        for q in st.session_state.quiz_data:
            st.subheader(f"{q['id']}. {q['question']}")
            user_choice = st.radio(f"Select:", q['options'], index=None, key=f"q_{q['id']}")
            
            if st.button(f"ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© {q['id']}", key=f"btn_{q['id']}"):
                if user_choice == q['correct_answer']:
                    st.success("âœ… Ø¥Ø¬Ø§Ø¨Ø© ØµØ­ÙŠØ­Ø©!")
                elif user_choice:
                    st.error(f"âŒ Ø®Ø·Ø£. Ø§Ù„ØµØ­ÙŠØ­: {q['correct_answer']}")
                st.info(f"ğŸ’¡ {q['explanation']}")
            st.markdown("---")
            
        if st.button("ğŸ”„ Ø§Ø®ØªØ¨Ø§Ø± Ø¬Ø¯ÙŠØ¯"):
            st.session_state.quiz_data = None
            st.rerun()

if __name__ == '__main__':
    main()
